{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nandaniyadav/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nandaniyadav/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/nandaniyadav/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nandaniyadav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255045\n",
       "1    149306\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks at our disposal\n",
    "#### 1. EDA\n",
    "#### 2. Data Cleaning - Stopwords , Alphanucmeric only\n",
    "#### 3. Feature Engineering - Vectorizers\n",
    "#### 4. Model Building - train/test split , initial model. Parameteization with updating model params and corpus methods like vectorizer etc \n",
    "#### 5. Model Evaluation - COnfusion matrix , metrics peresicion recall accuracy f1\n",
    "#### 6. Hosting on streamlit\n",
    "#### 7. 2 page report\n",
    "#### 8. Video recording\n",
    "#### 9. Presentation 15 mins in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape:  (404351, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       1\n",
       "question2       2\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset Shape\n",
    "print(\"dataframe shape: \",data.shape)\n",
    "\n",
    "#null vs not null\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove null values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nandaniyadav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>clean_question1</th>\n",
       "      <th>clean_question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>story kohinoor koh noor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>internet speed increased hacking dns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder 23 power 24 divided 24 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2  is_duplicate  \\\n",
       "0   0     1     2             0   \n",
       "1   1     3     4             0   \n",
       "2   2     5     6             0   \n",
       "3   3     7     8             0   \n",
       "4   4     9    10             0   \n",
       "\n",
       "                                     clean_question1  \\\n",
       "0          step step guide invest share market india   \n",
       "1                    story kohinoor koh noor diamond   \n",
       "2       increase speed internet connection using vpn   \n",
       "3                              mentally lonely solve   \n",
       "4  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                     clean_question2  \n",
       "0                step step guide invest share market  \n",
       "1  would happen indian government stole kohinoor ...  \n",
       "2               internet speed increased hacking dns  \n",
       "3           find remainder 23 power 24 divided 24 23  \n",
       "4                      fish would survive salt water  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords from NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    # Dictionary of English contractions\n",
    "    contractions_dict = {\"don't\": \"do not\", \"doesn't\": \"does not\", \"didn't\": \"did not\",\n",
    "                         # Add more contractions as needed\n",
    "                        }\n",
    "    # Regular expression for finding contractions\n",
    "    contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "#function to handle LaTeX expressions\n",
    "def clean_math_text(text):\n",
    "\n",
    "    replacements = {\n",
    "        # Basic operations and structures\n",
    "        r'\\\\frac\\{(.*?)\\}\\{(.*?)\\}': r'\\1 over \\2',\n",
    "        r'\\\\sqrt\\{(.*?)\\}': r'square root of \\1',\n",
    "        r'\\\\sum_(\\{.*?\\})\\^(\\{.*?\\})': r'sum from \\1 to \\2',\n",
    "        r'\\\\int_(\\{.*?\\})\\^(\\{.*?\\})': r'integral from \\1 to \\2',\n",
    "        r'\\\\log_(\\{.*?\\})\\{(.*?)\\}': r'log base \\1 of \\2',\n",
    "        r'\\\\lim_(\\{.*?\\})': r'limit as \\1',\n",
    "        r'(\\d+)\\^(\\{?\\d+\\}?)': r'\\1 to the power of \\2',\n",
    "        r'\\\\infty': 'infinity',\n",
    "        r'\\\\pm': 'plus or minus',\n",
    "        # Greek letters\n",
    "        r'\\\\alpha': 'alpha', r'\\\\beta': 'beta', r'\\\\gamma': 'gamma',\n",
    "        r'\\\\delta': 'delta', r'\\\\epsilon': 'epsilon', r'\\\\zeta': 'zeta',\n",
    "        r'\\\\eta': 'eta', r'\\\\theta': 'theta', r'\\\\iota': 'iota',\n",
    "        r'\\\\kappa': 'kappa', r'\\\\lambda': 'lambda', r'\\\\mu': 'mu',\n",
    "        r'\\\\nu': 'nu', r'\\\\xi': 'xi', r'\\\\omicron': 'omicron',\n",
    "        r'\\\\pi': 'pi', r'\\\\rho': 'rho', r'\\\\sigma': 'sigma',\n",
    "        r'\\\\tau': 'tau', r'\\\\upsilon': 'upsilon', r'\\\\phi': 'phi',\n",
    "        r'\\\\chi': 'chi', r'\\\\psi': 'psi', r'\\\\omega': 'omega',\n",
    "        # Trigonometric functions\n",
    "        r'\\\\sin': 'sine', r'\\\\cos': 'cosine', r'\\\\tan': 'tangent',\n",
    "        r'\\\\csc': 'cosecant', r'\\\\sec': 'secant', r'\\\\cot': 'cotangent',\n",
    "        # Differential and partial differential\n",
    "        r'\\\\partial': 'partial', r'\\\\nabla': 'nabla',\n",
    "        r'\\\\mathrm\\{d\\}': 'd',  # For derivatives\n",
    "        # Other mathematical symbols\n",
    "        r'\\\\times': 'times', r'\\\\div': 'divided by', r'\\\\cdot': 'dot',\n",
    "        # Additional symbols and operations\n",
    "        r'\\+': 'plus', r'\\-': 'minus', r'\\*': 'times',\n",
    "        # Handling general exponentiation\n",
    "        r'\\\\exp\\{(.*?)\\}': r'e to the power of \\1',  # For exponential functions\n",
    "        r'(\\w+)\\^(\\w+)': r'\\1 to the power of \\2',  # General exponentiation\n",
    "        # Handling \\mathop\n",
    "        r'\\\\mathop\\{\\\\rm ([^}]+)\\}': r'operator \\1'    }\n",
    "    \n",
    "    # Function to apply replacements to a matched object\n",
    "    def apply_replacements(match):\n",
    "        # Extracting the matched text excluding the [math] tags\n",
    "        math_text = match.group(1) # match.group(0) includes the whole match, so match.group(1) is the first capture group\n",
    "        \n",
    "        # Applying all replacements to the math_text\n",
    "        for pattern, replacement in replacements.items():\n",
    "            math_text = re.sub(pattern, replacement, math_text)\n",
    "        \n",
    "        # Return the transformed math_text\n",
    "        return math_text\n",
    "\n",
    "    # Use=ing re.sub with a function that applies the replacements for each [math] section\n",
    "    # Pattern captures the content between [math] and [/math] tags\n",
    "    pattern = r'\\[math\\](.*?)\\[/math\\]'\n",
    "    clean_text = re.sub(pattern, apply_replacements, text)\n",
    "\n",
    "    # Removing unnecessary braces and cleanup, applied globally to the whole text\n",
    "    clean_text = re.sub(r'\\{|\\}', '', clean_text)\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    #handling LaTex expressions\n",
    "    text = clean_math_text(text)\n",
    "    # Lowercase conversion\n",
    "    text = text.lower()\n",
    "    # Removing HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Removing URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Expanding contractions\n",
    "    text = expand_contractions(text)\n",
    "    # Removing special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Removing extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # removing stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Applying the cleaning function to DataFrame\n",
    "data['clean_question1'] = data['question1'].apply(clean_text)\n",
    "data['clean_question2'] = data['question2'].apply(clean_text)\n",
    "\n",
    "#dropping the original columns\n",
    "data.drop(['question1', 'question2'], axis=1, inplace=True)\n",
    "\n",
    "# Displaying the cleaned dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 404348 entries, 0 to 404350\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   id               404348 non-null  int64 \n",
      " 1   qid1             404348 non-null  int64 \n",
      " 2   qid2             404348 non-null  int64 \n",
      " 3   is_duplicate     404348 non-null  int64 \n",
      " 4   clean_question1  404348 non-null  object\n",
      " 5   clean_question2  404348 non-null  object\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 21.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Lemmatization using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DO not run, just for reference\n",
    "# Loading spaCy's English language model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Function to lemmatize text\n",
    "# def lemmatize_text(text):\n",
    "#     doc = nlp(text)\n",
    "#     lemmatized_list = [token.lemma_ for token in doc if token.is_alpha]\n",
    "    \n",
    "#     return ' '.join(lemmatized_list)\n",
    "\n",
    "# data['clean_question1'] = data['clean_question1'].apply(lemmatize_text)\n",
    "# data['clean_question2'] = data['clean_question2'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>clean_question1</th>\n",
       "      <th>clean_question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>story kohinoor koh noor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>internet speed increased hacking dns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder 23 power 24 divided 24 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2  is_duplicate  \\\n",
       "0   0     1     2             0   \n",
       "1   1     3     4             0   \n",
       "2   2     5     6             0   \n",
       "3   3     7     8             0   \n",
       "4   4     9    10             0   \n",
       "\n",
       "                                     clean_question1  \\\n",
       "0          step step guide invest share market india   \n",
       "1                    story kohinoor koh noor diamond   \n",
       "2       increase speed internet connection using vpn   \n",
       "3                              mentally lonely solve   \n",
       "4  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                     clean_question2  \n",
       "0                step step guide invest share market  \n",
       "1  would happen indian government stole kohinoor ...  \n",
       "2               internet speed increased hacking dns  \n",
       "3           find remainder 23 power 24 divided 24 23  \n",
       "4                      fish would survive salt water  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Lemmatization using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " part of speech (POS) tagging is necessary for lemmatization in NLTK, especially in our use case of comparing questions to determine duplicates. The reason is that NLTK's lemmatization depends on POS tags to correctly identify the base form of words. Different words require different lemmatization processes based on their POS (e.g., verbs, nouns, adjectives). Without POS tagging, lemmatization may not accurately reduce words to their base or dictionary form, which could affect the comparison and analysis of question pairs for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    # if pd.isnull(sentence):  # Check if the sentence is NaN\n",
    "    #     return \"\"  # Return empty string for NaN values\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # Tag tokens with part-of-speech\n",
    "    pos_tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Function to convert nltk tag to wordnet tag\n",
    "    def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:          \n",
    "            return None\n",
    "    \n",
    "    # Lemmatize each token\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in pos_tagged:\n",
    "        wordnet_tag = nltk_tag_to_wordnet_tag(tag)\n",
    "        if wordnet_tag is not None:\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, wordnet_tag))\n",
    "        else:\n",
    "            lemmatized_sentence.append(word)\n",
    "    \n",
    "    # Reconstruct the sentence\n",
    "    return ' '.join(lemmatized_sentence)\n",
    "\n",
    "# Replace NaN values with an empty string and apply the lemmatization\n",
    "data['lemmatized_question1'] = data['clean_question1'].apply(lemmatize_sentence)\n",
    "data['lemmatized_question2'] = data['clean_question2'].apply(lemmatize_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed with Lemmatization using NLTK and POS tagging. It is more faster that SpaCy and we have a large dataset to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a new column to find the length of the questions\n",
    "data['len_q1'] = data['lemmatized_question1'].apply(lambda x: len(x))\n",
    "data['len_q2'] = data['lemmatized_question2'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving cleaned file as csv\n",
    "data.to_csv('cleaned_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>clean_question1</th>\n",
       "      <th>clean_question2</th>\n",
       "      <th>lemmatized_question1</th>\n",
       "      <th>lemmatized_question2</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>story kohinoor koh noor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "      <td>story kohinoor koh noor diamond</td>\n",
       "      <td>would happen indian government steal kohinoor ...</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>internet speed increased hacking dns</td>\n",
       "      <td>increase speed internet connection use vpn</td>\n",
       "      <td>internet speed increase hack dns</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder 23 power 24 divided 24 23</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder 23 power 24 divide 24 23</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2  is_duplicate  \\\n",
       "0   0     1     2             0   \n",
       "1   1     3     4             0   \n",
       "2   2     5     6             0   \n",
       "3   3     7     8             0   \n",
       "4   4     9    10             0   \n",
       "\n",
       "                                     clean_question1  \\\n",
       "0          step step guide invest share market india   \n",
       "1                    story kohinoor koh noor diamond   \n",
       "2       increase speed internet connection using vpn   \n",
       "3                              mentally lonely solve   \n",
       "4  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                     clean_question2  \\\n",
       "0                step step guide invest share market   \n",
       "1  would happen indian government stole kohinoor ...   \n",
       "2               internet speed increased hacking dns   \n",
       "3           find remainder 23 power 24 divided 24 23   \n",
       "4                      fish would survive salt water   \n",
       "\n",
       "                                lemmatized_question1  \\\n",
       "0          step step guide invest share market india   \n",
       "1                    story kohinoor koh noor diamond   \n",
       "2         increase speed internet connection use vpn   \n",
       "3                              mentally lonely solve   \n",
       "4  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                lemmatized_question2  len_q1  len_q2  \n",
       "0                step step guide invest share market      41      35  \n",
       "1  would happen indian government steal kohinoor ...      31      67  \n",
       "2                   internet speed increase hack dns      42      32  \n",
       "3            find remainder 23 power 24 divide 24 23      21      39  \n",
       "4                      fish would survive salt water      60      29  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Vectorising using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404348, 69029), (404348, 69029))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vecoring the q1 and q2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_q1 = tfidf.fit_transform(data['q1_clean'])\n",
    "tfidf_q2 = tfidf.transform(data['q2_clean'])\n",
    "\n",
    "tfidf_q1.shape, tfidf_q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "step step guide invest share market india\n",
      "  (0, 31162)\t0.20685307207285322\n",
      "  (0, 38279)\t0.2879106302305413\n",
      "  (0, 55758)\t0.33466054360188274\n",
      "  (0, 32212)\t0.3263199368967071\n",
      "  (0, 27487)\t0.406764291381842\n",
      "  (0, 58540)\t0.7002711661711661 \n",
      "\n",
      "What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
      "story kohinoor kohinoor diamond\n",
      "  (0, 19131)\t0.3614777376192901\n",
      "  (0, 34844)\t0.895095953812048\n",
      "  (0, 58733)\t0.261030800241925\n"
     ]
    }
   ],
   "source": [
    "#printing a single vecotor of q1\n",
    "print(data['question1'][0])\n",
    "print(data['q1_clean'][0])\n",
    "print(tfidf_q1[0],\"\\n\")\n",
    "\n",
    "print(data['question1'][1])\n",
    "print(data['q1_clean'][1])\n",
    "print(tfidf_q1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Vectorising using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government steal kohinoor ...</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>[story, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, steal, koh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>increase speed internet connection use vpn</td>\n",
       "      <td>internet speed increase hack dns</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>[increase, speed, internet, connection, use, vpn]</td>\n",
       "      <td>[internet, speed, increase, hack, dns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder math2324math divide 2423</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "      <td>[mentally, lonely, solve]</td>\n",
       "      <td>[find, remainder, math2324math, divide, 2423]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>[one, dissolve, water, quikly, sugar, salt, me...</td>\n",
       "      <td>[fish, would, survive, salt, water]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                            q1_clean  \\\n",
       "0          step step guide invest share market india   \n",
       "1                    story kohinoor kohinoor diamond   \n",
       "2         increase speed internet connection use vpn   \n",
       "3                              mentally lonely solve   \n",
       "4  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                            q2_clean  len_q1  len_q2  \\\n",
       "0                step step guide invest share market      41      35   \n",
       "1  would happen indian government steal kohinoor ...      31      67   \n",
       "2                   internet speed increase hack dns      42      32   \n",
       "3            find remainder math2324math divide 2423      21      39   \n",
       "4                      fish would survive salt water      60      29   \n",
       "\n",
       "                                           q1_tokens  \\\n",
       "0  [step, step, guide, invest, share, market, india]   \n",
       "1               [story, kohinoor, kohinoor, diamond]   \n",
       "2  [increase, speed, internet, connection, use, vpn]   \n",
       "3                          [mentally, lonely, solve]   \n",
       "4  [one, dissolve, water, quikly, sugar, salt, me...   \n",
       "\n",
       "                                           q2_tokens  \n",
       "0         [step, step, guide, invest, share, market]  \n",
       "1  [would, happen, indian, government, steal, koh...  \n",
       "2             [internet, speed, increase, hack, dns]  \n",
       "3      [find, remainder, math2324math, divide, 2423]  \n",
       "4                [fish, would, survive, salt, water]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vecotorising using word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#tokenizing the questions\n",
    "data['q1_tokens'] = data['q1_clean'].apply(lambda x: word_tokenize(x))\n",
    "data['q2_tokens'] = data['q2_clean'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404348, 100), (404348, 100))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining tokens from q1 and q2 for training the Word2Vec model\n",
    "combined_tokens = data['q1_tokens'].tolist() + data['q2_tokens'].tolist()\n",
    "\n",
    "# Training the Word2Vec model\n",
    "model = Word2Vec(combined_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.train(combined_tokens, total_examples=model.corpus_count, epochs=10)\n",
    "\n",
    "# Adjusting the get_average_word2vec function to work with the vector model and tokens\n",
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=100):\n",
    "    if len(tokens_list) < 1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "# Adjusting the get_word2vec_embeddings function to handle both q1 and q2\n",
    "def get_word2vec_embeddings(vectors, tokens):\n",
    "    embeddings = tokens.apply(lambda x: get_average_word2vec(x, vectors))\n",
    "    return list(embeddings)\n",
    "\n",
    "# Applying the function to get the Word2Vec embeddings for both questions\n",
    "q1_embeddings = get_word2vec_embeddings(model.wv, data['q1_tokens'])\n",
    "q2_embeddings = get_word2vec_embeddings(model.wv, data['q2_tokens'])\n",
    "\n",
    "# Verifying the shape of the embeddings\n",
    "np.array(q1_embeddings).shape, np.array(q2_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "step step guide invest share market india\n",
      "['step', 'step', 'guide', 'invest', 'share', 'market', 'india']\n",
      "[-0.3253462   0.26244473 -0.08660941  0.37559232 -0.163662   -0.4149309\n",
      "  0.7285487  -0.25965905 -0.24108954  0.4867224   0.14792326  0.37749586\n",
      "  0.42332098  0.61909854  0.33205995 -0.432712   -0.11139467 -0.09459262\n",
      " -0.02723896  0.29754353  1.2064008   0.5660844  -1.7789133  -0.11842483\n",
      "  1.3022009  -1.3495013  -0.25312966 -0.39462867 -1.2683771   0.5267576\n",
      " -0.13193925 -0.24340534  0.54764193 -0.8048476  -0.28579298 -0.41477618\n",
      " -0.282823    1.0840447   0.528861   -0.32653052 -1.5251633  -0.54182595\n",
      "  0.30241483  0.2887678  -1.1410592   0.8777286   0.74321955 -1.486635\n",
      "  0.7986768   0.01431977  1.2304507   0.92896974 -0.5894543   0.5027923\n",
      "  0.60770565 -0.11172057 -0.4060655  -0.08909579  0.01043369  0.22586478\n",
      " -2.0197217   0.47006813 -0.37562582  0.5702934   0.40824673 -0.82841676\n",
      " -0.5137155   0.02935838  0.17145602 -0.36627403 -1.0980189  -0.22455962\n",
      " -1.6716455  -0.14825208  0.13840394 -0.89968646 -0.0866258  -0.4937941\n",
      "  1.2956692  -0.5184936   0.19304715 -1.3991982   0.16423921  0.15785168\n",
      "  0.11062571 -0.20177849  0.36096573 -0.12239051 -0.17010863  2.056247\n",
      "  0.17846362  0.66863066  0.45003408 -1.7414662   0.08161879 -0.77933484\n",
      "  0.30669972  1.1457218  -0.09936552  0.8358501 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing the embeddings\n",
    "\n",
    "print(data['question1'][0])\n",
    "print(data['q1_clean'][0])\n",
    "print(data['q1_tokens'][0])\n",
    "print(q1_embeddings[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
