{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Testing all possible models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash Joshi\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Accuracy  F1 Score\n",
      "0   Logistic Regression    0.7130  0.591168\n",
      "1         Random Forest    0.7305  0.586973\n",
      "2     Gradient Boosting    0.7480  0.642553\n",
      "3                   SVC    0.7560  0.647399\n",
      "4    MLP Neural Network    0.7370  0.651194\n",
      "5  Gaussian Naive Bayes    0.6600  0.578686\n",
      "6                   KNN    0.7115  0.578524\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the data\n",
    "nltk_data = pd.read_csv('nltk_embeddings.csv')\n",
    "spacy_data = pd.read_csv('spacy_embeddings.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['id', 'qid1', 'qid2', 'clean_question1', 'clean_question2']\n",
    "nltk_data.drop(columns=columns_to_drop, inplace=True)\n",
    "spacy_data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Combining NLTK and spaCy embeddings\n",
    "combined_data = pd.concat([nltk_data.drop(columns='is_duplicate'), spacy_data.drop(columns='is_duplicate')], axis=1)\n",
    "target = spacy_data['is_duplicate']  # Assuming is_duplicate columns are the same in both dataframes\n",
    "\n",
    "# Separate features and target\n",
    "X = combined_data\n",
    "y = target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a list to store results\n",
    "results = []\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, name):\n",
    "    pipeline = make_pipeline(StandardScaler(), model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    results.append((name, accuracy, f1))\n",
    "\n",
    "# Models to evaluate\n",
    "models = [\n",
    "    (LogisticRegression(), \"Logistic Regression\"),\n",
    "    (RandomForestClassifier(), \"Random Forest\"),\n",
    "    (GradientBoostingClassifier(), \"Gradient Boosting\"),\n",
    "    (SVC(), \"SVC\"),\n",
    "    (MLPClassifier(max_iter=300), \"MLP Neural Network\"),\n",
    "    (GaussianNB(), \"Gaussian Naive Bayes\"),\n",
    "    (KNeighborsClassifier(), \"KNN\")\n",
    "]\n",
    "\n",
    "# Evaluate models\n",
    "for model, name in models:\n",
    "    evaluate_model(model, name)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1 Score'])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Fine tuning top 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash Joshi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Model: SVC\n",
      "Best Score: 0.75725\n",
      "Best Parameters: {'SVC__C': 1, 'SVC__gamma': 'scale', 'SVC__kernel': 'rbf'}\n",
      "\n",
      "Model: MLP\n",
      "Best Score: 0.7415\n",
      "Best Parameters: {'MLP__activation': 'relu', 'MLP__hidden_layer_sizes': (50,), 'MLP__learning_rate_init': 0.001, 'MLP__solver': 'sgd'}\n",
      "\n",
      "Model: GradientBoosting\n",
      "Best Score: 0.7565000000000001\n",
      "Best Parameters: {'GradientBoosting__learning_rate': 0.1, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 200}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define pipelines for each model with StandardScaler and the model\n",
    "pipelines = {\n",
    "    'SVC': Pipeline([('scaler', StandardScaler()), ('SVC', SVC())]),\n",
    "    'MLP': Pipeline([('scaler', StandardScaler()), ('MLP', MLPClassifier(max_iter=300))]),\n",
    "    'GradientBoosting': Pipeline([('scaler', StandardScaler()), ('GradientBoosting', GradientBoostingClassifier())]),\n",
    "}\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    'SVC': {\n",
    "        'SVC__C': [0.1, 1, 10],\n",
    "        'SVC__kernel': ['linear', 'rbf'],\n",
    "        'SVC__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'MLP': {\n",
    "        'MLP__hidden_layer_sizes': [(50,), (100,), (50,50)],\n",
    "        'MLP__activation': ['relu', 'tanh'],\n",
    "        'MLP__solver': ['adam', 'sgd'],\n",
    "        'MLP__learning_rate_init': [0.001, 0.01],\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'GradientBoosting__n_estimators': [100, 200],\n",
    "        'GradientBoosting__learning_rate': [0.01, 0.1],\n",
    "        'GradientBoosting__max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "tuning_results = {}\n",
    "\n",
    "# Perform grid search for each model\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    grid_search = GridSearchCV(pipeline, param_grids[model_name], cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    tuning_results[model_name] = {'Best Model': best_model, 'Best Params': best_params, 'Best Score': best_score}\n",
    "\n",
    "# Display fine-tuning results\n",
    "for model_name, results in tuning_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Best Score: {results['Best Score']}\")\n",
    "    print(f\"Best Parameters: {results['Best Params']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
